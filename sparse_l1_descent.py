from tqdm import tqdm
import argparse
import torch
import os
import torchvision.transforms as T
import numpy as np
import json
import transformers
from PIL import Image

# def get_different_class(c_true, classes):
#     classes_kept = [c for c in classes if c != c_true]
#     chosen_class = np.random.choice(classes_kept)
#     return classes.index(chosen_class) 

def get_different_class(c_true, classes):
    classes_kept = [c for c in classes if c != c_true]
    new_class_idx = np.random.choice(classes_kept)
    new_label = classes.index(new_class_idx) 
    new_label = torch.tensor(new_label).unsqueeze(0).cuda()
    return new_label

def boolean_string(s):
    if s not in {'False', 'True'}:
        raise ValueError('Not a valid boolean string')
    return s == 'True'


def print_clip_top_probs(logits_per_image, classes):
    """
    Print the top 5 class probabilities for a given image based on its logits.
    :param logits_per_image: Tensor of logits per image generated by the vision model.
    :param classes: List of class names corresponding to each logit in the tensor.
    """

    probs = logits_per_image.softmax(dim=1)
    # print(probs)
    top_probs_scaled, top_idxs_scaled = probs[0].topk(5)

    if classes != None:
        for i in range(top_probs_scaled.shape[0]):
            print(f"{classes[top_idxs_scaled[i]]}: {top_probs_scaled[i].item() * 100:.2f}%")   

def clip_model_fn(x, text_embeds, vision_model, classes=None):
    """
    Compute CLIP similarity scores between an image and a set of text embeddings.
    :param x: Image tensor.
    :param text_embeddings: Precomputed text embeddings for all labels.
    :return: Similarity scores between the image and all text labels.
    """

    logit_scale = 2.6592
    logit_scale = torch.tensor(logit_scale).exp()

    image_embeds = vision_model(x).image_embeds.half()
    image_embeds = image_embeds / image_embeds.norm(p=2, dim=-1, keepdim=True)
    logits_per_image = torch.matmul(image_embeds, text_embeds.t()) * logit_scale

    print_clip_top_probs(logits_per_image, classes)

    return logits_per_image

def generate_adversary(image, text_embeddings, vision_model, target_label):

    adv_image = sparse_l1_descent(
        model_fn=lambda x: clip_model_fn(x, text_embeddings, vision_model, classes=None),
        x=image,
        eps=100.0,
        eps_iter=1.0,
        nb_iter=100,
        y=target_label,
        targeted=True,
        clip_min=0,
        clip_max=1,
        rand_init=False,
        clip_grad=False,
        grad_sparsity=99,
        sanity_checks=False,
    )
    return adv_image


# Generate many adversarial examples using PGD attack
def generate_adversarials_pgd(args):

    f = open(args.label_list, 'r')
    label_names = list(json.load(f).keys())
    f.close()

    label_all = []

    for v in label_names:
        label_all.append("a photo of %s"%v)

    f = open(args.image_list, 'r')
    image_list = f.readlines()
    f.close()

    vision_model = transformers.CLIPVisionModelWithProjection.from_pretrained("openai/clip-vit-large-patch14", torch_dtype=torch.float16).cuda()
    text_model = transformers.CLIPTextModelWithProjection.from_pretrained("openai/clip-vit-large-patch14", torch_dtype=torch.float16).cuda()
    tokenizer = transformers.AutoTokenizer.from_pretrained("openai/clip-vit-large-patch14")

    test_transform = T.Compose([
        T.Resize(size=(224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),
    ])

    denormalize = T.Normalize((-0.485/0.229, -0.456/0.224, -0.406/0.225), (1/0.229, 1/0.224, 1/0.225)) # for denormalizing images
     
    vision_model.eval()
    text_model.eval()

    image_list = image_list[args.set*args.set_num:(args.set+1)*args.set_num]

    with torch.no_grad():
        text_labels = tokenizer(label_all, padding=True, return_tensors="pt")['input_ids'].cuda()
        text_label_embeds = text_model(text_labels).text_embeds
        text_label_embeds = text_label_embeds / text_label_embeds.norm(p=2, dim=-1, keepdim=True)

    correct = 0
    num_total = 0

    for i, data in tqdm( enumerate(image_list)):

        num_total += 1

        image_name, label_name = data.split('|')
        base_name = os.path.basename(image_name)
        image = Image.open(image_name).convert('RGB')
        image = test_transform(image).cuda().half().unsqueeze(0)

        ## Text label embedding
        label_name = label_name.split('\n')[0]
        label_name = "a photo of " + label_name

        # print('\nProbabilities pre-attack:')
        pre_attack_logits_per_image = clip_model_fn(image, text_label_embeds, vision_model, label_all)

        target_label = get_different_class(label_name, label_all)


        # Generate adversarial
        adv_image = generate_adversary(image=image,
                                       text_embeddings=text_label_embeds,
                                        vision_model=vision_model,
                                        target_label = target_label)
        
        denormalized_tensor = denormalize(adv_image)

        print("Probabilities post-attack")
        post_attack_logits_per_image = clip_model_fn(denormalized_tensor, text_label_embeds, vision_model, label_all)

        if torch.argmax(pre_attack_logits_per_image) == torch.argmax(post_attack_logits_per_image):
            correct += 1

        save_image = denormalized_tensor.squeeze(0)
        save_image = T.ToPILImage()(save_image)


        if args.save_image: 
            os.makedirs(f"/home/crcvreu.student2/coco/sparse_l1_descent_rgb", exist_ok=True)
            save_image.save(f'/home/crcvreu.student2/coco/sparse_l1_descent_rgb/{base_name}')

        tmp = image_name.split(os.sep)
        os.makedirs(f"/home/crcvreu.student2/coco/sparse_l1_descent", exist_ok=True)
        tmp[tmp.index('trainval2014')] = 'sparse_l1_descent'
        save_name = os.path.splitext(os.sep + os.path.join(*tmp))[0] + ".pt"
        torch.save(denormalized_tensor, save_name)
    
    print(f'Correct! Total % correct: {correct / num_total}')


def sparse_l1_descent(
    model_fn,
    x,
    eps=10.0,
    eps_iter=1.0,
    nb_iter=20,
    y=None,
    targeted=False,
    clip_min=None,
    clip_max=None,
    rand_init=True,
    clip_grad=False,
    grad_sparsity=99,
    sanity_checks=True,
):
    """
    This class implements a variant of Projected Gradient Descent for the l1-norm
    (Tramer and Boneh 2019). The l1-norm case is more tricky than the l-inf and l2
    cases covered by the ProjectedGradientDescent class, because the steepest
    descent direction for the l1-norm is too sparse (it updates a single
    coordinate in the adversarial perturbation in each step). This attack has an
    additional parameter that controls the sparsity of the update step. For
    moderately sparse update steps, the attack vastly outperforms Projected
    Steepest Descent and is competitive with other attacks targeted at the l1-norm
    such as the ElasticNetMethod attack (which is much more computationally
    expensive).
    Paper link (Tramer and Boneh 2019): https://arxiv.org/pdf/1904.13000.pdf

    :param model_fn: a callable that takes an input tensor and returns the model logits.
    :param x: input tensor.
    :param eps: (optional float) maximum distortion of adversarial example
        compared to original input
    :param eps_iter: (optional float) step size for each attack iteration
    :param nb_iter: (optional int) Number of attack iterations.
    :param y: (optional) A tensor with the true labels.
    :param targeted: (optional) bool. Is the attack targeted or untargeted?
        Untargeted, the default, will try to make the label incorrect.
        Targeted will instead try to move in the direction of being more like y.
    :param clip_min: (optional float) Minimum input component value
    :param clip_max: (optional float) Maximum input component value
    :param clip_grad: (optional bool) Ignore gradient components
        at positions where the input is already at the boundary
        of the domain, and the update step will get clipped out.
    :param grad_sparsity (optional) Relative sparsity of the gradient update
        step, in percent. Only gradient values larger
        than this percentile are retained. This parameter can
        be a scalar, or a tensor of the same length as the
        input batch dimension.
    :param sanity_checks: bool, if True, include asserts (Turn them off to use less runtime /
        memory or for unit tests that intentionally pass strange input)
    :return: a tensor for the adversarial examples
    """
    if clip_grad and (clip_min is None or clip_max is None):
        raise ValueError("Must set clip_min and clip_max if clip_grad is set")

    # The grad_sparsity argument governs the sparsity of the gradient
    # update. It indicates the percentile value above which gradient entries
    # are retained. It can be specified as a scalar or as a 1-dimensional
    # tensor of the same size as the input's batch dimension.
    if isinstance(grad_sparsity, int) or isinstance(grad_sparsity, float):
        if not 0 < grad_sparsity < 100:
            raise ValueError("grad_sparsity should be in (0, 100)")
    else:
        grad_sparsity = torch.tensor(grad_sparsity)
        if len(grad_sparsity.shape) > 1:
            raise ValueError("grad_sparsity should either be a scalar or a tensor")
        grad_sparsity = grad_sparsity.to(x.device)
        if grad_sparsity.shape[0] != x.shape[0]:
            raise ValueError(
                "grad_sparsity should have same length as input if it is a tensor"
            )

    asserts = []

    # eps_iter should be at most eps
    asserts.append(eps_iter <= eps)

    # If a data range was specified, check that the input was in that range
    if clip_min is not None:
        assert_ge = torch.all(
            torch.ge(x, torch.tensor(clip_min, device=x.device, dtype=x.dtype))
        )
        asserts.append(assert_ge)

    if clip_max is not None:
        assert_le = torch.all(
            torch.le(x, torch.tensor(clip_max, device=x.device, dtype=x.dtype))
        )
        asserts.append(assert_le)

    if sanity_checks:
        assert np.all(asserts)

    # Initialize loop variables
    if rand_init:
        dist = torch.distributions.laplace.Laplace(
            torch.tensor([1.0]), torch.tensor([1.0])
        )
        dim = torch.prod(torch.tensor(x.shape[1:]))
        eta = dist.sample([x.shape[0], dim]).squeeze(-1).to(x.device)
        norm = torch.sum(torch.abs(eta), axis=-1, keepdim=True)
        w = torch.pow(
            torch.rand(x.shape[0], 1, device=x.device), torch.tensor(1.0 / dim)
        )
        eta = torch.reshape(eps * (w * eta / norm), x.shape)
    else:
        eta = torch.zeros_like(x)

    # Clip eta
    adv_x = x.clone().detach().requires_grad_(True)
    eta = eta.renorm(p=1, dim=0, maxnorm=eps)
    adv_x = adv_x + eta

    if clip_min is not None or clip_max is not None:
        adv_x = torch.clamp(x, clip_min, clip_max)

    if y is None:
        y = torch.argmax(model_fn(x), 1)

    criterion = torch.nn.CrossEntropyLoss(reduction="none")
    for i in range(nb_iter):
        adv_x = adv_x.clone().detach().to(torch.float16).requires_grad_(True)
        logits = model_fn(adv_x)

        # Compute loss
        loss = criterion(logits, y)
        if targeted:
            loss = -loss

        # Define gradient of loss wrt input
        (grad,) = torch.autograd.grad(loss.mean(), [adv_x])

        if clip_grad:
            grad = zero_out_clipped_grads(grad, adv_x, clip_min, clip_max)

        grad_view = grad.view(grad.shape[0], -1)
        abs_grad = torch.abs(grad_view)

        if isinstance(grad_sparsity, int) or isinstance(grad_sparsity, float):
            k = int(grad_sparsity / 100.0 * abs_grad.shape[1])
            percentile_value, _ = torch.kthvalue(abs_grad, k, keepdim=True)
        else:
            k = (grad_sparsity / 100.0 * abs_grad.shape[1]).long()
            percentile_value, _ = torch.sort(abs_grad, dim=1)
            percentile_value = percentile_value.gather(1, k.view(-1, 1))

        percentile_value = percentile_value.repeat(1, grad_view.shape[1])
        tied_for_max = torch.ge(abs_grad, percentile_value).int().half()
        num_ties = torch.sum(tied_for_max, dim=1, keepdim=True)

        optimal_perturbation = (torch.sign(grad_view) * tied_for_max) / num_ties
        optimal_perturbation = optimal_perturbation.view(grad.shape)

        # Add perturbation to original example to obtain adversarial example
        adv_x = adv_x + optimal_perturbation * eps_iter

        # If clipping is needed, reset all values outside of [clip_min, clip_max]
        if clip_min is not None or clip_max is not None:
            adv_x = torch.clamp(adv_x, clip_min, clip_max)

        # Clipping perturbation eta to the l1-ball
        eta = adv_x - x
        eta = eta.renorm(p=1, dim=0, maxnorm=eps)
        adv_x = x + eta

        # Redo the clipping.
        # Subtracting and re-adding eta can add some small numerical error.
        if clip_min is not None or clip_max is not None:
            adv_x = torch.clamp(adv_x, clip_min, clip_max)

    return adv_x.detach()

# Taken from cleverhans library
def zero_out_clipped_grads(grad, x, clip_min, clip_max):
    """
    Helper function to erase entries in the gradient where the update would be
    clipped.
    :param grad: The gradient
    :param x: The current input
    :param clip_min: Minimum input component value
    :param clip_max: Maximum input component value
    """
    signed_grad = torch.sign(grad)

    # Find input components that lie at the boundary of the input range, and
    # where the gradient points in the wrong direction.
    clip_low = torch.le(x, clip_min) & torch.lt(signed_grad, 0)
    clip_high = torch.ge(x, clip_max) & torch.gt(signed_grad, 0)
    clip = clip_low | clip_high
    grad = torch.where(clip, torch.zeros_like(grad), grad)

    return grad

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # parser.add_argument("--image_name", type=str, default="zebra.jpeg")
    parser.add_argument("--image_list", type=str, default="./coco_test.txt")
    parser.add_argument("--label_list", type=str, default="./coco_label.json")
    parser.add_argument("--attack_type", type=str, default="sparse_l1_descent", required=False)
    parser.add_argument("--set", type=int, required=True)
    parser.add_argument("--set_num", type=int, required=True)
    parser.add_argument("--save_image", type=boolean_string, required=False, default='False')

    args = parser.parse_args()

    generate_adversarials_pgd(args)

    # python carlini_wagner.py --set 0 --set_num 1 --save_image True