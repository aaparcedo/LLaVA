


def recall_at_k(image_encodings, text_encodings, text_to_image_map, image_to_text_map, k_vals: List[int]):
     
    num_text = text_encodings.shape[0]
    num_im = image_encodings.shape[0]
    captions_per_image = image_to_text_map.shape[1]

    dist_matrix = text_encodings @ image_encodings.T 
    dist_matrix = dist_matrix.cpu()

    inds = torch.argsort(dist_matrix, dim=1, descending=True)
    inds = inds.to(device)

    text_to_image_recall = []

    for k in k_vals:
        topk = inds[:, :k]
        correct = torch.eq(topk, text_to_image_map.unsqueeze(-1)).any(dim=1)
        num_correct = correct.sum().item()
        text_to_image_recall.append(num_correct / num_text)

    dist_matrix = dist_matrix.T
    inds = torch.argsort(dist_matrix, dim=1, descending=True)
    inds = inds.to(device)

    image_to_text_recall = []

    for k in k_vals:
        topk = inds[:, :k]

        correct = torch.zeros((num_im,), dtype=torch.bool).cuda()
        for i in range(captions_per_image):
            contains_index = torch.eq(topk, image_to_text_map[:, i].unsqueeze(-1)).any(dim=1)
            correct = torch.logical_or(correct, contains_index)

        num_correct = correct.sum().item()
        image_to_text_recall.append(num_correct / num_im)#

    return text_to_image_recall, image_to_text_recall

